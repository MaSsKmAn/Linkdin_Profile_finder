{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e9b06e67a7b54a3e90d8356309288186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_212243c2fc7e4c59a12527bc4eb3ddb0",
              "IPY_MODEL_3f98ddb5e60d4d31b8b66d13a6fb94e6",
              "IPY_MODEL_bd24874c14d84f40b2732d52ed48b2d5"
            ],
            "layout": "IPY_MODEL_065e854d64ac42368ebb0af0bcb86e51"
          }
        },
        "212243c2fc7e4c59a12527bc4eb3ddb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48775a54150a4666986576e7c9237c1a",
            "placeholder": "​",
            "style": "IPY_MODEL_9892ae3b13b84026bd2bb7ea63a8f23b",
            "value": "open_clip_model.safetensors: 100%"
          }
        },
        "3f98ddb5e60d4d31b8b66d13a6fb94e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d70c9dd41a994c2486e35ec60a316e80",
            "max": 605143316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e7a404f54cc4e5ba004a8579d75a4b2",
            "value": 605143316
          }
        },
        "bd24874c14d84f40b2732d52ed48b2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8bfeb81b644490097d380b035b87892",
            "placeholder": "​",
            "style": "IPY_MODEL_b7368a1c3a7b4ea1b436436242946f52",
            "value": " 605M/605M [00:04&lt;00:00, 160MB/s]"
          }
        },
        "065e854d64ac42368ebb0af0bcb86e51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48775a54150a4666986576e7c9237c1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9892ae3b13b84026bd2bb7ea63a8f23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d70c9dd41a994c2486e35ec60a316e80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e7a404f54cc4e5ba004a8579d75a4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a8bfeb81b644490097d380b035b87892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7368a1c3a7b4ea1b436436242946f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Importing the Libraries"
      ],
      "metadata": {
        "id": "p0Pv_6q_a4l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO"
      ],
      "metadata": {
        "id": "XphSvAf6FdIL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the dataset:\n",
        "Replace the dataset link with the dataset you want to add."
      ],
      "metadata": {
        "id": "kBNLWropa-EL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xBJ566NYFKNP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "with open('dataset1.json', 'r') as file:\n",
        "    data_list = json.load(file)\n",
        "\n",
        "processed = []\n",
        "for entry in data_list:\n",
        "    name_cleaned = re.sub(r\"\\(.*?\\)\", \"\", entry.get(\"name\", \"\")).strip()\n",
        "\n",
        "    # Insert space before uppercase letter that follows a lowercase letter\n",
        "    formatted_name = re.sub(r\"(?<=[a-z])(?=[A-Z])\", \" \", name_cleaned)\n",
        "\n",
        "    if entry.get(\"timezone\") and \"/\" in entry[\"timezone\"]:\n",
        "        country, state = entry[\"timezone\"].split(\"/\")\n",
        "    else:\n",
        "        country, state = \"\", \"\"\n",
        "\n",
        "    company_size = entry.get(\"company_size\") or \"\"\n",
        "    company_industry = entry.get(\"company_industry\") or \"\"\n",
        "    company_info = re.sub(r'\\s+', ' ', f\"{company_size} {company_industry}\").strip()\n",
        "\n",
        "    intro = re.sub(r'\\s+', ' ', entry.get(\"intro\") or \"\").strip()\n",
        "    image = entry.get(\"image\") or \"\"\n",
        "\n",
        "    processed.append({\n",
        "        \"name\": formatted_name,\n",
        "        \"intro\": intro,\n",
        "        \"state\": state,\n",
        "        \"country\": country,\n",
        "        \"company_info\": company_info,\n",
        "        \"image\": image\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(processed)"
      ],
      "metadata": {
        "id": "CqQ9zV30Ff0T"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gZSxmFsI6ZnE",
        "outputId": "f96dd21f-cab0-4aaa-c8a9-76d99dc5db06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               name                                              intro  \\\n",
              "0       Zach Hawtof  Community Leader. Occasional CEO. Tightknit (h...   \n",
              "1        Derek Koch  The Seeker (https://theseeker.storychamp.commu...   \n",
              "2          Damion W                        Principal Security Engineer   \n",
              "3         Eric Doty                Content Lead @ Dock / Superpath Mod   \n",
              "4    Sadri Follador                                                      \n",
              "5      Jeff Ignacio                      Head of RevOps at Keystone AI   \n",
              "6     Kevin Burnett  software developer, spiffworkflow, lover of de...   \n",
              "7     Gaurav Nemade  Co-founder @ Inventive.ai (RFP + AI) | YC, Fou...   \n",
              "8   Manoj Ranaweera  Techcelerate + Deal Lite + SkilledUp Life (htt...   \n",
              "9          Ihor Der  Founder of M1-project.com (https://www.m1-proj...   \n",
              "10       Chris Hill  3x CEO, 4x Senior Director of Rev Ops - Murrie...   \n",
              "11      Raja Vijaya                                                      \n",
              "\n",
              "          state  country company_info  \\\n",
              "0      New_York  America                \n",
              "1       Chicago  America                \n",
              "2      New_York  America                \n",
              "3   Los_Angeles  America                \n",
              "4      Brussels   Europe                \n",
              "5   Los_Angeles  America                \n",
              "6      Monrovia   Africa                \n",
              "7       Kolkata     Asia           AI   \n",
              "8        London   Europe         Tech   \n",
              "9     Jerusalem     Asia                \n",
              "10  Los_Angeles  America                \n",
              "11       London   Europe                \n",
              "\n",
              "                                                image  \n",
              "0   https://drive.google.com/file/d/1G4nkXOR_f-RGK...  \n",
              "1   https://drive.google.com/file/d/1ON-0Ka1UHxedx...  \n",
              "2   https://drive.google.com/file/d/1EGZ9-pwlPSg3V...  \n",
              "3   https://drive.google.com/file/d/1VaRq5MEihND-Y...  \n",
              "4   https://drive.google.com/file/d/1Xaiz6s9w4sKiy...  \n",
              "5   https://drive.google.com/file/d/1sY4FWAmHdeOj8...  \n",
              "6   https://drive.google.com/file/d/1IQ_5p9emMC8LQ...  \n",
              "7   https://drive.google.com/file/d/1IgK6_gHu4lM55...  \n",
              "8   https://drive.google.com/file/d/1i86Q1Yhi6TpA7...  \n",
              "9   https://drive.google.com/file/d/1I5KCB4Vu-ZuPw...  \n",
              "10  https://drive.google.com/file/d/19T7DfiIu9SnYG...  \n",
              "11  https://drive.google.com/file/d/1D_354XYuDGxrk...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f5310bb-7ed4-4af3-a847-3c45b8765d76\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>intro</th>\n",
              "      <th>state</th>\n",
              "      <th>country</th>\n",
              "      <th>company_info</th>\n",
              "      <th>image</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Zach Hawtof</td>\n",
              "      <td>Community Leader. Occasional CEO. Tightknit (h...</td>\n",
              "      <td>New_York</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1G4nkXOR_f-RGK...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Derek Koch</td>\n",
              "      <td>The Seeker (https://theseeker.storychamp.commu...</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1ON-0Ka1UHxedx...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Damion W</td>\n",
              "      <td>Principal Security Engineer</td>\n",
              "      <td>New_York</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1EGZ9-pwlPSg3V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Eric Doty</td>\n",
              "      <td>Content Lead @ Dock / Superpath Mod</td>\n",
              "      <td>Los_Angeles</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1VaRq5MEihND-Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sadri Follador</td>\n",
              "      <td></td>\n",
              "      <td>Brussels</td>\n",
              "      <td>Europe</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1Xaiz6s9w4sKiy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Jeff Ignacio</td>\n",
              "      <td>Head of RevOps at Keystone AI</td>\n",
              "      <td>Los_Angeles</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1sY4FWAmHdeOj8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Kevin Burnett</td>\n",
              "      <td>software developer, spiffworkflow, lover of de...</td>\n",
              "      <td>Monrovia</td>\n",
              "      <td>Africa</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1IQ_5p9emMC8LQ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Gaurav Nemade</td>\n",
              "      <td>Co-founder @ Inventive.ai (RFP + AI) | YC, Fou...</td>\n",
              "      <td>Kolkata</td>\n",
              "      <td>Asia</td>\n",
              "      <td>AI</td>\n",
              "      <td>https://drive.google.com/file/d/1IgK6_gHu4lM55...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Manoj Ranaweera</td>\n",
              "      <td>Techcelerate + Deal Lite + SkilledUp Life (htt...</td>\n",
              "      <td>London</td>\n",
              "      <td>Europe</td>\n",
              "      <td>Tech</td>\n",
              "      <td>https://drive.google.com/file/d/1i86Q1Yhi6TpA7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Ihor Der</td>\n",
              "      <td>Founder of M1-project.com (https://www.m1-proj...</td>\n",
              "      <td>Jerusalem</td>\n",
              "      <td>Asia</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1I5KCB4Vu-ZuPw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Chris Hill</td>\n",
              "      <td>3x CEO, 4x Senior Director of Rev Ops - Murrie...</td>\n",
              "      <td>Los_Angeles</td>\n",
              "      <td>America</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/19T7DfiIu9SnYG...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Raja Vijaya</td>\n",
              "      <td></td>\n",
              "      <td>London</td>\n",
              "      <td>Europe</td>\n",
              "      <td></td>\n",
              "      <td>https://drive.google.com/file/d/1D_354XYuDGxrk...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f5310bb-7ed4-4af3-a847-3c45b8765d76')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f5310bb-7ed4-4af3-a847-3c45b8765d76 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f5310bb-7ed4-4af3-a847-3c45b8765d76');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-47b9c0d8-cf51-454c-b96e-2ab1714ee3a0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47b9c0d8-cf51-454c-b96e-2ab1714ee3a0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-47b9c0d8-cf51-454c-b96e-2ab1714ee3a0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df1",
              "summary": "{\n  \"name\": \"df1\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"Chris Hill\",\n          \"Ihor Der\",\n          \"Zach Hawtof\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"intro\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Head of RevOps at Keystone AI\",\n          \"Community Leader. Occasional CEO. Tightknit (https://community.tightknit.ai)\",\n          \"Founder of M1-project.com (https://www.m1-project.com/?utm_source=revgenius)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"Chicago\",\n          \"Kolkata\",\n          \"New_York\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Europe\",\n          \"Asia\",\n          \"America\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"company_info\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"\",\n          \"AI\",\n          \"Tech\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"https://drive.google.com/file/d/19T7DfiIu9SnYGW5acMzwl0BbgYVhyr-h/view?usp=drive_link\",\n          \"https://drive.google.com/file/d/1I5KCB4Vu-ZuPwO5qLzLoypcnDjTAkZRj/view?usp=drive_link\",\n          \"https://drive.google.com/file/d/1G4nkXOR_f-RGKdXw0HJctVmVVcSU6VS2/view?usp=drive_link\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the Linkdin profile and giving the information inside of it in dataframe\n",
        "We have first analysed the components present in json data of the linkdin file and developed a mechanism to extract the key components her in the form of a dataframe."
      ],
      "metadata": {
        "id": "41BmK2EGbIsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "# ---------------------------\n",
        "# 🔍 LinkedIn Profile Search\n",
        "# ---------------------------\n",
        "def get_linkedin_profiles(name, max_pages=3):\n",
        "    query = f'\"{name}\" site:linkedin.com/in'\n",
        "    base_url = 'https://html.duckduckgo.com/html/'\n",
        "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "    linkedin_links = set()\n",
        "    current_page = 0\n",
        "    params = {'q': query}\n",
        "\n",
        "    while current_page < max_pages:\n",
        "        response = requests.post(base_url, headers=headers, data=params)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        results = soup.find_all('a', href=True)\n",
        "\n",
        "        for result in results:\n",
        "            href = result['href']\n",
        "            if 'linkedin.com/in/' in href and name.lower() in result.get_text().lower():\n",
        "                linkedin_links.add(href)\n",
        "\n",
        "        next_form = soup.find('form', class_='results_links_more')\n",
        "        if next_form:\n",
        "            params = {inp['name']: inp.get('value', '') for inp in next_form.find_all('input')}\n",
        "            current_page += 1\n",
        "            time.sleep(1)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    return list(linkedin_links)\n",
        "\n",
        "# ---------------------------\n",
        "# 🤖 Bot Mimicry Headers\n",
        "# ---------------------------\n",
        "user_agents = [\n",
        "    \"Slackbot-LinkExpanding 1.0 (+https://api.slack.com/robots)\",\n",
        "    \"LinkedInBot/1.0\",\n",
        "    \"Twitterbot/1.0\",\n",
        "    \"facebookexternalhit/1.1\",\n",
        "    \"WhatsApp/2.0\",\n",
        "    \"Googlebot/2.1 (+http://www.google.com/bot.html)\"\n",
        "]\n",
        "user_agent_cycle = itertools.cycle(user_agents)\n",
        "\n",
        "def mimic_bot_headers() -> str:\n",
        "    return next(user_agent_cycle)\n",
        "\n",
        "# ---------------------------\n",
        "# 🕵️ LinkedIn Profile Fetcher\n",
        "# ---------------------------\n",
        "class LinkedInRawFetcher:\n",
        "    def __init__(self):\n",
        "        self.proxies = {\n",
        "            \"https\": \"http://brd-customer-hl_6c1f36a6-zone-datacenter_proxy1:ssv7js44jm4x@brd.superproxy.io:33335\",\n",
        "            \"http\": \"http://brd-customer-hl_6c1f36a6-zone-datacenter_proxy1:ssv7js44jm4x@brd.superproxy.io:33335\"\n",
        "        }\n",
        "\n",
        "    def fetch(self, url: str) -> str:\n",
        "        for _ in range(3):\n",
        "            headers = {\"User-Agent\": mimic_bot_headers()}\n",
        "            try:\n",
        "                response = requests.get(url, headers=headers, proxies=self.proxies)\n",
        "                if response.status_code == 200:\n",
        "                    return response.text\n",
        "            except Exception as e:\n",
        "                print(f\"Request failed for {url}: {e}\")\n",
        "        print(f\"Failed to fetch URL: {url}\")\n",
        "        return \"\"\n",
        "\n",
        "def get_interaction_count(statistics, target_type):\n",
        "    for x in statistics:\n",
        "        interaction_type = x.get(\"interactionType\")\n",
        "        interaction_id = interaction_type.get(\"@id\") if isinstance(interaction_type, dict) else interaction_type\n",
        "        if interaction_id == target_type:\n",
        "            return x.get(\"userInteractionCount\")\n",
        "    return None\n",
        "\n",
        "# ---------------------------\n",
        "# 🧼 Clean and Parse HTML\n",
        "# ---------------------------\n",
        "def process_linkedin_url(url, fetcher):\n",
        "    raw_html = fetcher.fetch(url)\n",
        "    if not raw_html:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    soup = BeautifulSoup(raw_html, 'html.parser')\n",
        "    ld_json_script = soup.find(\"script\", {\"type\": \"application/ld+json\"})\n",
        "    ld_data = json.loads(ld_json_script.string) if ld_json_script and ld_json_script.string else {}\n",
        "\n",
        "    main_entity = ld_data.get(\"mainEntity\", {})\n",
        "    statistics = main_entity.get(\"interactionStatistic\", [])\n",
        "\n",
        "    cleaned_data = {\n",
        "        \"profile_url\": url,\n",
        "        \"full_name\": main_entity.get(\"name\"),\n",
        "        \"first_name\": soup.find(\"meta\", {\"property\": \"profile:first_name\"})[\"content\"] if soup.find(\"meta\", {\"property\": \"profile:first_name\"}) else None,\n",
        "        \"last_name\": soup.find(\"meta\", {\"property\": \"profile:last_name\"})[\"content\"] if soup.find(\"meta\", {\"property\": \"profile:last_name\"}) else None,\n",
        "        \"profile_image\": main_entity.get(\"image\", {}).get(\"contentUrl\"),\n",
        "        \"headline\": main_entity.get(\"description\"),\n",
        "        \"location\": {\n",
        "            \"city\": main_entity.get(\"address\", {}).get(\"addressLocality\"),\n",
        "            \"state\": \"Rajasthan\",\n",
        "            \"country\": main_entity.get(\"address\", {}).get(\"addressCountry\")\n",
        "        },\n",
        "        \"experience\": [\n",
        "            {\n",
        "                \"position\": role.get(\"jobTitle\") if role else None,\n",
        "                \"organization\": org.get(\"name\"),\n",
        "                \"location\": org.get(\"location\") if \"location\" in org else None,\n",
        "                \"url\": org.get(\"url\")\n",
        "            } for org in main_entity.get(\"worksFor\", []) for role in [org.get(\"member\", {})]\n",
        "        ],\n",
        "        \"education\": [\n",
        "            {\n",
        "                \"institute\": edu.get(\"name\"),\n",
        "                \"url\": edu.get(\"url\"),\n",
        "                \"start_date\": edu.get(\"member\", {}).get(\"startDate\"),\n",
        "                \"end_date\": edu.get(\"member\", {}).get(\"endDate\")\n",
        "            } for edu in main_entity.get(\"alumniOf\", [])\n",
        "        ],\n",
        "        \"awards\": main_entity.get(\"awards\", []),\n",
        "        \"connections\": get_interaction_count(statistics, \"https://schema.org/BefriendAction\"),\n",
        "        \"followers\": get_interaction_count(statistics, \"https://schema.org/FollowAction\"),\n",
        "        \"og_title\": soup.find(\"meta\", {\"property\": \"og:title\"})[\"content\"] if soup.find(\"meta\", {\"property\": \"og:title\"}) else None,\n",
        "        \"meta_description\": soup.find(\"meta\", {\"name\": \"description\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"description\"}) else None,\n",
        "        \"twitter_card\": {\n",
        "            \"card\": soup.find(\"meta\", {\"name\": \"twitter:card\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"twitter:card\"}) else None,\n",
        "            \"site\": soup.find(\"meta\", {\"name\": \"twitter:site\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"twitter:site\"}) else None,\n",
        "            \"title\": soup.find(\"meta\", {\"name\": \"twitter:title\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"twitter:title\"}) else None,\n",
        "            \"description\": soup.find(\"meta\", {\"name\": \"twitter:description\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"twitter:description\"}) else None,\n",
        "            \"image\": soup.find(\"meta\", {\"name\": \"twitter:image\"})[\"content\"] if soup.find(\"meta\", {\"name\": \"twitter:image\"}) else None\n",
        "        }\n",
        "    }\n",
        "\n",
        "    location = cleaned_data.get(\"location\", {})\n",
        "    city_state_country = [i.strip() for i in f\"{location.get('city', '')}, {location.get('state', '')}, {location.get('country', '')}\".split(\",\")]\n",
        "    cleaned_data[\"location_city\"] = city_state_country[0] if len(city_state_country) > 0 else None\n",
        "    cleaned_data[\"location_state\"] = city_state_country[1] if len(city_state_country) > 1 else None\n",
        "    cleaned_data[\"location_country\"] = city_state_country[2] if len(city_state_country) > 2 else None\n",
        "    cleaned_data.pop(\"location\", None)\n",
        "\n",
        "    experience_data = []\n",
        "    for exp in cleaned_data.get(\"experience\", []):\n",
        "        parts = [x.strip() for x in (exp.get(\"location\") or \"\").split(\",\")]\n",
        "        city, state, country = (parts + [\"\"] * 3)[:3]\n",
        "        experience_data.append({\n",
        "            \"position\": exp.get(\"position\"),\n",
        "            \"organization\": exp.get(\"organization\"),\n",
        "            \"exp_url\": exp.get(\"url\"),\n",
        "            \"exp_location_city\": city,\n",
        "            \"exp_location_state\": state,\n",
        "            \"exp_location_country\": country\n",
        "        })\n",
        "    cleaned_data.pop(\"experience\", None)\n",
        "\n",
        "    education_data = []\n",
        "    for edu in cleaned_data.get(\"education\", []):\n",
        "        education_data.append({\n",
        "            \"institute\": edu.get(\"institute\"),\n",
        "            \"edu_url\": edu.get(\"url\"),\n",
        "            \"edu_start_date\": edu.get(\"start_date\"),\n",
        "            \"edu_end_date\": edu.get(\"end_date\"),\n",
        "        })\n",
        "    cleaned_data.pop(\"education\", None)\n",
        "\n",
        "    for key, val in cleaned_data.get(\"twitter_card\", {}).items():\n",
        "        cleaned_data[f\"twitter_{key}\"] = val\n",
        "    cleaned_data.pop(\"twitter_card\", None)\n",
        "\n",
        "    combined_data = []\n",
        "    for exp in experience_data or [{}]:\n",
        "        for edu in education_data or [{}]:\n",
        "            combined_data.append({**cleaned_data, **exp, **edu})\n",
        "\n",
        "    return pd.DataFrame(combined_data)\n",
        "\n",
        "# ---------------------------\n",
        "# 🚀 Main Execution\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    name_input = \"Derek Koch\"\n",
        "    profile_urls = get_linkedin_profiles(name_input)\n",
        "\n",
        "    fetcher = LinkedInRawFetcher()\n",
        "    all_data = []\n",
        "\n",
        "    for url in profile_urls:\n",
        "        df = process_linkedin_url(url, fetcher)\n",
        "        if not df.empty:\n",
        "            all_data.append(df)\n",
        "\n",
        "    final_df = pd.concat(all_data, ignore_index=True)\n",
        "    final_df.drop_duplicates(subset=[\"profile_url\", \"full_name\"], inplace=True)\n",
        "    final_df.to_csv(\"linkedin_profiles_combined.csv\", index=False)\n",
        "    print(final_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrESyA3AKzr3",
        "outputId": "8e3f21e7-e9b7-418d-bfbf-baa673c182fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to fetch URL: https://www.linkedin.com/in/derek-koch\n",
            "                                        profile_url full_name first_name  \\\n",
            "0             https://www.linkedin.com/in/derekkoch      None      Derek   \n",
            "1            https://www.linkedin.com/in/derekmkoch      None      Derek   \n",
            "2            https://www.linkedin.com/in/derekekoch      None      Derek   \n",
            "3  https://www.linkedin.com/in/derek-koch-42092a260      None      Derek   \n",
            "4             https://www.linkedin.com/in/kochderek      None      Derek   \n",
            "\n",
            "  last_name profile_image headline awards connections followers  \\\n",
            "0      Koch          None     None     []        None      None   \n",
            "1      Koch          None     None     []        None      None   \n",
            "2      Koch          None     None     []        None      None   \n",
            "3      Koch          None     None     []        None      None   \n",
            "4      Koch          None     None     []        None      None   \n",
            "\n",
            "                                            og_title  ... position  \\\n",
            "0             Derek Koch - Embodied Labs® | LinkedIn  ...      NaN   \n",
            "1  Derek Koch - Koch Capital Partners, LP | LinkedIn  ...      NaN   \n",
            "2                       Derek Koch - Team | LinkedIn  ...      NaN   \n",
            "3        Derek Koch - Veritiv Corporation | LinkedIn  ...      NaN   \n",
            "4        Derek Koch - M&amp;S Engineering | LinkedIn  ...      NaN   \n",
            "\n",
            "  organization exp_url exp_location_city exp_location_state  \\\n",
            "0          NaN     NaN               NaN                NaN   \n",
            "1          NaN     NaN               NaN                NaN   \n",
            "2          NaN     NaN               NaN                NaN   \n",
            "3          NaN     NaN               NaN                NaN   \n",
            "4          NaN     NaN               NaN                NaN   \n",
            "\n",
            "  exp_location_country institute edu_url edu_start_date edu_end_date  \n",
            "0                  NaN       NaN     NaN            NaN          NaN  \n",
            "1                  NaN       NaN     NaN            NaN          NaN  \n",
            "2                  NaN       NaN     NaN            NaN          NaN  \n",
            "3                  NaN       NaN     NaN            NaN          NaN  \n",
            "4                  NaN       NaN     NaN            NaN          NaN  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####In this code we have looked into a single profile because scraping has a limit in colab.\n",
        "\n",
        "\"Name\":\"Derek Koch\""
      ],
      "metadata": {
        "id": "sNCXgo1ndcTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.read_csv('/content/linkedin_profiles_combined.csv')"
      ],
      "metadata": {
        "id": "vT6M_RA7SkoT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1=df1[df1[\"name\"]==\"Derek Koch\"]"
      ],
      "metadata": {
        "id": "G38bR2i8TWEe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are components of the columns which are null so there will be further steps ahead where we have to ingnore them because they are not originally in the dataset."
      ],
      "metadata": {
        "id": "wNMpnKF_b1s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-9XVyIGTZKH",
        "outputId": "9b9ce2c1-11a9-4e2d-cd3a-fb5f92348bf3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['profile_url', 'full_name', 'first_name', 'last_name', 'profile_image',\n",
              "       'headline', 'awards', 'connections', 'followers', 'og_title',\n",
              "       'meta_description', 'location_city', 'location_state',\n",
              "       'location_country', 'twitter_site', 'twitter_title',\n",
              "       'twitter_description', 'twitter_image', 'position', 'organization',\n",
              "       'exp_url', 'exp_location_city', 'exp_location_state',\n",
              "       'exp_location_country', 'institute', 'edu_url', 'edu_start_date',\n",
              "       'edu_end_date'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Similarity search for different components of the original dataset\n",
        "\n",
        " A similarity matrix will be created for each and every step in this."
      ],
      "metadata": {
        "id": "UPkUpxxTdAke"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step1: Checking whether the name is same or not.\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "innE9JFDdGpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "def calculate_cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_a = np.linalg.norm(vec1)\n",
        "    norm_b = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm_a * norm_b)\n",
        "\n",
        "def construct_similarity_matrix(df1, df2):\n",
        "    similarity_matrix = []\n",
        "\n",
        "    for index1, row1 in df1.iterrows():\n",
        "        sim_row = []\n",
        "\n",
        "        for index2, row2 in df2.iterrows():\n",
        "            full_name_df2 = f\"{row2['first_name']} {row2['last_name']}\"\n",
        "\n",
        "            name_similarity = calculate_cosine_similarity(\n",
        "                get_bert_embedding(row1['name']),\n",
        "                get_bert_embedding(full_name_df2)\n",
        "            )\n",
        "\n",
        "            sim_row.append(name_similarity)\n",
        "\n",
        "        similarity_matrix.append(sim_row)\n",
        "\n",
        "    similarity_df = pd.DataFrame(similarity_matrix, columns=[f'{i}' for i in range(len(df2))])\n",
        "\n",
        "    return similarity_df\n",
        "\n",
        "similarity_df3 = construct_similarity_matrix(df1, df2)\n",
        "print(\"Similarity Matrix:\\n\", similarity_df3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePG7fR-8Vp0B",
        "outputId": "505bd602-54b5-43cb-ba68-ff8972ea29fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity Matrix:\n",
            "      0    1    2    3    4    5    6    7    8\n",
            "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step2: Checking whether the country and state is same or not."
      ],
      "metadata": {
        "id": "2byYdv3ndvC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Mean pooling\n",
        "\n",
        "def construct_similarity_matrix(df1, df2):\n",
        "    similarity_matrix = []\n",
        "\n",
        "    for index1, row1 in df1.iterrows():\n",
        "        sim_row = []\n",
        "\n",
        "        for index2, row2 in df2.iterrows():\n",
        "            # Get BERT embeddings for the country and state\n",
        "            country_bert_embedding_df1 = get_bert_embedding(str(row1['country']))\n",
        "            location_country_bert_embedding_df2 = get_bert_embedding(str(row2['location_country']))\n",
        "            state_bert_embedding_df1 = get_bert_embedding(str(row1['state']))\n",
        "            location_state_bert_embedding_df2 = get_bert_embedding(str(row2['location_state']))\n",
        "\n",
        "            # Calculate cosine similarity between BERT embeddings for country and state\n",
        "            country_similarity = cosine_similarity([country_bert_embedding_df1], [location_country_bert_embedding_df2])[0][0]\n",
        "            state_similarity = cosine_similarity([state_bert_embedding_df1], [location_state_bert_embedding_df2])[0][0]\n",
        "\n",
        "            # Combine country and state similarity scores\n",
        "            combined_similarity = country_similarity + state_similarity\n",
        "\n",
        "            # Append the combined similarity to the row\n",
        "            sim_row.append(combined_similarity)\n",
        "\n",
        "        # Append each row to the similarity matrix\n",
        "        similarity_matrix.append(sim_row)\n",
        "\n",
        "    # Convert similarity matrix to a DataFrame for better readability\n",
        "    similarity_df = pd.DataFrame(similarity_matrix, columns=[f'{i}' for i in range(len(df2))])\n",
        "\n",
        "    return similarity_df\n",
        "\n",
        "# Example usage: assuming df1 and df2 are already loaded as pandas DataFrames\n",
        "similarity_df2 = construct_similarity_matrix(df1, df2)\n",
        "\n",
        "# Display the similarity matrix\n",
        "print(\"Combined Similarity Matrix:\\n\", similarity_df2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1kkh7ombfOk",
        "outputId": "5a946ff6-f153-4068-8de8-841683ad30d6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Similarity Matrix:\n",
            "           0         1         2         3         4        5         6  \\\n",
            "0  1.665291  1.665291  1.665291  1.665291  1.665291  1.66849  1.665291   \n",
            "\n",
            "          7         8  \n",
            "0  1.665291  1.665291  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step3:Checking whether the image is same or not.\n",
        " Using clip to check the similarity and similarity score will be created for it. some will have nan beacuse there is no image for them."
      ],
      "metadata": {
        "id": "kw-zXJCCd15d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install open-clip-torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8Q1HzjSvfjmH",
        "outputId": "451595c5-0a1a-4a6e-f10b-beee2027eb58"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting open-clip-torch\n",
            "  Downloading open_clip_torch-2.32.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.21.0+cu124)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (2024.11.6)\n",
            "Collecting ftfy (from open-clip-torch)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.30.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (0.5.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from open-clip-torch) (1.0.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9.0->open-clip-torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9.0->open-clip-torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9.0->open-clip-torch) (1.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open-clip-torch) (0.2.13)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open-clip-torch) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open-clip-torch) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9.0->open-clip-torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open-clip-torch) (2025.1.31)\n",
            "Downloading open_clip_torch-2.32.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, open-clip-torch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open-clip-torch-2.32.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "nvidia"
                ]
              },
              "id": "fea88f3dd225402babbdc13b48520a56"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "import torch\n",
        "import open_clip\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "model, preprocess, tokenizer = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "def download_image(url, save_as):\n",
        "    try:\n",
        "        if pd.isna(url):\n",
        "            print(f\"Skipping invalid URL: {url}\")\n",
        "            return None\n",
        "        if \"drive.google.com\" in url:\n",
        "            file_id = url.split('/d/')[1].split('/')[0]\n",
        "            url = f\"https://drive.google.com/uc?export=download&id={file_id}\"\n",
        "\n",
        "        response = requests.get(url, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            with open(save_as, \"wb\") as f:\n",
        "                f.write(response.content)\n",
        "            return save_as\n",
        "        else:\n",
        "            print(f\"Failed to download {url} — Status code: {response.status_code}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading {url}: {e}\")\n",
        "    return None\n",
        "def get_clip_embedding(image_path):\n",
        "    try:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_input = preprocess(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            image_features = model.encode_image(image_input)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        return image_features.cpu().numpy()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {e}\")\n",
        "        return None\n",
        "def process_df(df, column_name, prefix):\n",
        "    embeddings = []\n",
        "    for idx, row in df.iterrows():\n",
        "        url = row[column_name]\n",
        "        filename = f\"{prefix}_{idx}.jpg\"\n",
        "        path = download_image(url, filename)\n",
        "        if path:\n",
        "            embedding = get_clip_embedding(path)\n",
        "            embeddings.append(embedding)\n",
        "        else:\n",
        "            embeddings.append(None)\n",
        "    return embeddings\n",
        "def calculate_similarity(embeddings1, embeddings2):\n",
        "    similarities = []\n",
        "    for emb1 in embeddings1:\n",
        "        if emb1 is not None:\n",
        "            for emb2 in embeddings2:\n",
        "                if emb2 is not None:\n",
        "                    sim = np.dot(emb1.flatten(), emb2.flatten()) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
        "                    similarities.append(sim)\n",
        "                else:\n",
        "                    similarities.append(0)\n",
        "        else:\n",
        "            similarities.append(0)\n",
        "    return similarities\n",
        "df1['embedding'] = process_df(df1, 'image', 'df1_img')\n",
        "df2['embedding'] = process_df(df2, 'profile_image', 'df2_img')\n",
        "similarities = calculate_similarity(df1['embedding'], df2['embedding'])\n",
        "similarity_matrix1 = pd.DataFrame(np.array(similarities).reshape(len(df1), len(df2)),\n",
        "                                 columns=[f'{i}' for i in range(len(df2))])\n",
        "print(\"Similarity Matrix:\\n\", similarity_matrix1)\n",
        "most_similar_idx = np.unravel_index(np.argmax(similarity_matrix1.values), similarity_matrix1.shape)\n",
        "print(f\"The most similar images are from df1 index {most_similar_idx[0]} and df2 index {most_similar_idx[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "e9b06e67a7b54a3e90d8356309288186",
            "212243c2fc7e4c59a12527bc4eb3ddb0",
            "3f98ddb5e60d4d31b8b66d13a6fb94e6",
            "bd24874c14d84f40b2732d52ed48b2d5",
            "065e854d64ac42368ebb0af0bcb86e51",
            "48775a54150a4666986576e7c9237c1a",
            "9892ae3b13b84026bd2bb7ea63a8f23b",
            "d70c9dd41a994c2486e35ec60a316e80",
            "9e7a404f54cc4e5ba004a8579d75a4b2",
            "a8bfeb81b644490097d380b035b87892",
            "b7368a1c3a7b4ea1b436436242946f52"
          ]
        },
        "id": "rG_nvyHBjLj5",
        "outputId": "b2df05ca-f974-449c-c48d-776d748b77fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9b06e67a7b54a3e90d8356309288186"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Skipping invalid URL: nan\n",
            "Similarity Matrix:\n",
            "      0    1    2    3    4         5    6    7    8\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.385686  0.0  0.0  0.0\n",
            "The most similar images are from df1 index 0 and df2 index 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step4: Checking whether the intro matches."
      ],
      "metadata": {
        "id": "UuI2mEcoeM35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_profile_to_string(df):\n",
        "    def profile_to_string(row):\n",
        "        profile_data = []\n",
        "\n",
        "        for col in row.index:\n",
        "            value = row[col]\n",
        "\n",
        "            try:\n",
        "                if isinstance(value, (list, dict, np.ndarray)):\n",
        "                    value = str(value)\n",
        "\n",
        "                if pd.notnull(value):\n",
        "                    string_value = str(value).strip()\n",
        "                    if string_value:\n",
        "                        profile_data.append(string_value)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing column {col} with value {value}: {e}\")\n",
        "\n",
        "        return ' '.join(profile_data)\n",
        "\n",
        "    profile_series = df.apply(profile_to_string, axis=1)\n",
        "    return profile_series\n",
        "\n",
        "df2[\"profile_strings\"] = convert_profile_to_string(df2)\n",
        "# print(f\"Expected: {len(df2)}, Got: {len(profile_strings)} rows\")\n",
        "print(df2[\"profile_strings\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbQfCRbymgTB",
        "outputId": "8af0370b-a75c-4c61-8042-47e253ac0b1f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    https://www.linkedin.com/in/derekkoch Derek Ko...\n",
            "1    https://www.linkedin.com/in/derekmkoch Derek K...\n",
            "2    https://www.linkedin.com/in/derekekoch Derek K...\n",
            "3    https://www.linkedin.com/in/derek-koch-42092a2...\n",
            "4    https://www.linkedin.com/in/kochderek Derek Ko...\n",
            "5    https://www.linkedin.com/in/derek-koch-192bb12...\n",
            "6    https://www.linkedin.com/in/derek-koch-2161b41...\n",
            "7    https://www.linkedin.com/in/derek-koch-802ab27...\n",
            "8    https://www.linkedin.com/in/derek-koch-7139772...\n",
            "Name: profile_strings, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "\n",
        "def compute_intro_profile_similarity(df1, profile_strings):\n",
        "    similarity_matrix = np.zeros((len(df1), len(profile_strings)))\n",
        "\n",
        "    for i, intro in enumerate(df1['intro']):\n",
        "        intro_embedding = get_bert_embedding(str(intro))\n",
        "\n",
        "        for j, profile_text in enumerate(profile_strings):\n",
        "            profile_embedding = get_bert_embedding(str(profile_text))\n",
        "            dot_product = np.dot(intro_embedding, profile_embedding)\n",
        "            norm_a = np.linalg.norm(intro_embedding)\n",
        "            norm_b = np.linalg.norm(profile_embedding)\n",
        "            similarity = dot_product / (norm_a * norm_b)\n",
        "\n",
        "            similarity_matrix[i, j] = similarity\n",
        "\n",
        "    return similarity_matrix\n",
        "\n",
        "similarity_matrix = compute_intro_profile_similarity(df1, df2[\"profile_strings\"])\n",
        "\n",
        "similarity_df = pd.DataFrame(similarity_matrix,\n",
        "                             index=[f\"{i}\" for i in range(len(df1))],\n",
        "                             columns=[f\"{j}\" for j in range(len( df2[\"profile_strings\"]))])\n",
        "\n",
        "print(similarity_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNACaellvayh",
        "outputId": "10f25fa6-dec4-4e88-8dbe-6605d47b2e7c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5        6  \\\n",
            "0  0.661928  0.632441  0.638573  0.635216  0.652231  0.654185  0.66296   \n",
            "\n",
            "          7         8  \n",
            "0  0.661984  0.651189  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Giving same index to all the similarity matrix"
      ],
      "metadata": {
        "id": "QH_glV1KedFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_index = similarity_df.index\n",
        "ref_columns = similarity_df.columns\n",
        "\n",
        "similarity_matrix1 = similarity_matrix1.copy()\n",
        "similarity_df2 = similarity_df2.copy()\n",
        "similarity_df3 = similarity_df3.copy()\n",
        "\n",
        "similarity_matrix1.index = ref_index\n",
        "similarity_matrix1.columns = ref_columns\n",
        "\n",
        "similarity_df2.index = ref_index\n",
        "similarity_df2.columns = ref_columns\n",
        "\n",
        "similarity_df3.index = ref_index\n",
        "similarity_df3.columns = ref_columns\n"
      ],
      "metadata": {
        "id": "edsq_wpgGqng"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Step 5:Giving the combined similarity score for the total above steps."
      ],
      "metadata": {
        "id": "50L1FM6SeiHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def weighted_similarity_matrix_df(matrices, weights):\n",
        "    weight_sum = sum(weights)\n",
        "    weights = [w / weight_sum for w in weights]\n",
        "\n",
        "    index = matrices[0].index\n",
        "    columns = matrices[0].columns\n",
        "    shape = matrices[0].shape\n",
        "\n",
        "    for m in matrices:\n",
        "        if m.shape != shape or not m.index.equals(index) or not m.columns.equals(columns):\n",
        "            raise ValueError(\"All DataFrames must have the same shape, index, and columns\")\n",
        "\n",
        "    final_df = sum(w * m for w, m in zip(weights, matrices))\n",
        "    return final_df\n",
        "\n",
        "weights = [0.5, 0.6, 0.2, 0.7]\n",
        "\n",
        "final_similarity_df = weighted_similarity_matrix_df(\n",
        "    [similarity_df, similarity_matrix1, similarity_df2, similarity_df3],\n",
        "    weights\n",
        ")\n",
        "\n",
        "print(final_similarity_df)\n"
      ],
      "metadata": {
        "id": "Lkr681AMvj3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e0f792-6da5-400f-d5f9-55e4b29f54df"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6  \\\n",
            "0  0.682011  0.674639  0.676172  0.675333  0.679587  0.796101  0.682269   \n",
            "\n",
            "          7         8  \n",
            "0  0.682025  0.679326  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####From the above code it is clear that 5 in the most similar"
      ],
      "metadata": {
        "id": "rk6KihyjeuMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"profile_url\"][5]"
      ],
      "metadata": {
        "id": "vNrfLI4dFUqQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d066063b-908d-4a7a-b99b-e718e4552272"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://www.linkedin.com/in/derek-koch-192bb120b'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RcfmEtJBe2Xk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}